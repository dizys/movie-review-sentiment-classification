{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\mhisf\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt.zip.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from argparse import Namespace\n",
    "import copy\n",
    "import gensim\n",
    "from gensim.models import Word2Vec\n",
    "import json\n",
    "import nltk; nltk.download('punkt')\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import urllib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = Namespace(\n",
    "    seed=1234,\n",
    "    data_file=\"language\\\\movie_corpus.txt\",\n",
    "    embedding_dim=100,\n",
    "    window=5,\n",
    "    min_count=3,\n",
    "    skip_gram=1, # 0 = CBOW\n",
    "    negative_sampling=20,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100013\n",
      "However, as this is a comedy, the duo manage to make the most round about and stupid escape--accidentally boarding a train to Constantinople to be placed in a Turkish prisoner of war camp!\n"
     ]
    }
   ],
   "source": [
    "# Split text into sentences\n",
    "tokenizer = nltk.data.load('tokenizers/punkt/english.pickle')\n",
    "with open(args.data_file, encoding='utf8') as fp:\n",
    "    book = fp.read()\n",
    "sentences = tokenizer.tokenize(book)\n",
    "print (len(sentences))\n",
    "print (sentences[11])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing\n",
    "def preprocess_text(text):\n",
    "    text = ' '.join(word.lower() for word in text.split(\" \"))\n",
    "    text = re.sub(r\"([.,!?])\", r\" \\1 \", text)\n",
    "    text = re.sub(r\"[^a-zA-Z.,!?]+\", r\" \", text)\n",
    "    text = text.strip()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "however , as this is a comedy , the duo manage to make the most round about and stupid escape accidentally boarding a train to constantinople to be placed in a turkish prisoner of war camp !\n"
     ]
    }
   ],
   "source": [
    "# Clean sentences\n",
    "sentences = [preprocess_text(sentence) for sentence in sentences]\n",
    "print (sentences[11])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['however', ',', 'as', 'this', 'is', 'a', 'comedy', ',', 'the', 'duo', 'manage', 'to', 'make', 'the', 'most', 'round', 'about', 'and', 'stupid', 'escape', 'accidentally', 'boarding', 'a', 'train', 'to', 'constantinople', 'to', 'be', 'placed', 'in', 'a', 'turkish', 'prisoner', 'of', 'war', 'camp', '!']\n"
     ]
    }
   ],
   "source": [
    "# Process sentences for gensim\n",
    "sentences = [sentence.split(\" \") for sentence in sentences]\n",
    "print (sentences[11])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['the',\n",
       " 'storyline',\n",
       " 'of',\n",
       " 'this',\n",
       " 'game',\n",
       " 'is',\n",
       " ',',\n",
       " 'i',\n",
       " 'think',\n",
       " 'one',\n",
       " 'of',\n",
       " 'the',\n",
       " 'greatest',\n",
       " 'from',\n",
       " 'the',\n",
       " 'final',\n",
       " 'fantasy',\n",
       " 'series',\n",
       " 'and',\n",
       " 'the',\n",
       " 'graphics',\n",
       " 'for',\n",
       " 'a',\n",
       " 'ps',\n",
       " 'video',\n",
       " 'game',\n",
       " ',',\n",
       " 'well',\n",
       " 'it',\n",
       " 'is',\n",
       " 'just',\n",
       " 'amazing',\n",
       " '.']"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(sentences[10111])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word2Vec(vocab=21750, size=100, alpha=0.025)\n"
     ]
    }
   ],
   "source": [
    "# Train Word2Vec model with sentences\n",
    "model = Word2Vec(sentences=sentences, size=args.embedding_dim, \n",
    "                 window=args.window, min_count=args.min_count, \n",
    "                 sg=args.skip_gram, negative=args.negative_sampling)\n",
    "print (model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('okay', 0.8580403923988342),\n",
       " ('alright', 0.8139011859893799),\n",
       " ('anyways', 0.770700216293335),\n",
       " ('horrid', 0.7692903280258179),\n",
       " ('dubbing', 0.768156886100769)]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar(positive=\"ok\", topn=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('language.w2v.model')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
